---
title: 'Week 5: Final'
author: "COVID Data Analysis"
date: "2/27/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Cleaning Data
We are going to be looking at COVID 19 cases in the US to see if there is a state that can be used as a predictor for other states. First we need to import and clean up our data. We're going to use the Johns Hopkin's data sets for the US since it's a reliable source. Then We're going to change the columns for each date into a row for each date with the new column value being number of cases. We'll also remote state location information since we don't need that and reformat the date field into a date datatype. Next we'll join the information on number of cases with the information on number of deaths into a single data set. 

```{r libraries}
library(tidyverse)
library(lubridate)
url_in <- "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/"
file_names <- c("time_series_covid19_confirmed_US.csv",
                "time_series_covid19_deaths_US.csv")
urls <- str_c(url_in, file_names)
US_cases <- read_csv(urls[1])
US_deaths <- read_csv(urls[2])
US_cases <- US_cases %>% pivot_longer(cols = -(UID:Combined_Key), names_to = "date", values_to = "cases") %>% select(Admin2:cases) %>% mutate(date = mdy(date)) %>% select(-c(Lat, Long_))
US_deaths <- US_deaths %>% pivot_longer(cols = -(UID:Population), names_to = "date", values_to = "deaths") %>% select(Admin2:deaths) %>% mutate(date = mdy(date)) %>% select(-c(Lat, Long_))
US <- US_cases %>% full_join(US_deaths)
summary(US)
```

Currently the state data is broken down by county, so we're going to change those into totals for the entire state and look at totals for the entire country.

```{r checkData}
US_by_state <- US %>% group_by(Province_State, Country_Region, date) %>% summarize(cases = sum(cases), deaths = sum(deaths), Population = sum(Population)) %>% mutate(deaths_per_mill = deaths * 1000000 / Population) %>% select(Province_State, Country_Region, date, cases, deaths, deaths_per_mill, Population) %>% ungroup()

US_totals <- US_by_state %>% group_by(Country_Region, date) %>% summarize(cases = sum(cases), deaths = sum(deaths), Population = sum(Population)) %>% mutate(deaths_per_mill = deaths * 1000000 / Population) %>% select(Country_Region, date, cases, deaths, deaths_per_mill, Population) %>% ungroup()

US_totals %>% filter(cases > 0) %>% ggplot(aes(x = date, y = cases)) + geom_line(aes(color = "cases")) + geom_point(aes(color = "cases")) + geom_line(aes(y = deaths, color = "deaths")) + geom_point(aes(y = deaths, color = "deaths")) + scale_y_log10() + theme(legend.position = "bottom", axis.text.x = element_text(angle = 90)) + labs(title = "COVID19 in US", y = NULL)
```

Taking a quick look at the graph of US totals (on a logarithmic scale) matches the expectations of what we've seen from other sources. Since our data looks good, let's add some extra fields that we may want for analysis. The cases and deaths are a running total, so let's add fields for the day to day change.

```{r addData}
US_by_state <- US_by_state %>% mutate(new_cases = cases - lag(cases), new_deaths = deaths - lag(deaths), cases_per_thou = cases * 1000 / Population, deaths_per_thou = deaths * 1000 / Population) %>% filter(cases > 0, Population > 0)
summary(US_by_state)

mod <- lm(deaths_per_thou ~ cases_per_thou, data = US_by_state)
summary(mod)
US_w_pred <- US_by_state %>% mutate(pred = predict(mod))
US_w_pred %>% ggplot() + geom_point(aes(x = cases_per_thou, y = deaths_per_thou), color = "blue") + geom_point(aes(x = cases_per_thou, y = pred), color = "red")
```

Import, tidy and analyze the COVID19 dataset from the Johns Hopkins github site. This is the same dataset I used in class. Feel free to repeat and reuse what I did if you want to. Be sure your project is reproducible and contains some visualization and analysis that is unique to your project. You may use the data to do any analysis that is of interest to you. You should include at least two visualizations and one model.  Be sure to identify any bias possible in the data and in your analysis.

Ideas: Predictor state per region? Predictor state for a group of states?
```{r testing}
States <- split(US_by_state, US_by_state$Province_State)
for(i in 1:length(States))
{
  States[i][[1]] <- States[i][[1]] %>% mutate(cases_per_thou = as.numeric(cases_per_thou)) %>% mutate(deaths_per_thou = as.numeric(deaths_per_thou))
}
```

```{r testPreds}
options(warn=-1)
sets = list(list())
models <- lapply(States, lm, formula = deaths_per_thou ~ cases_per_thou)
for(m in models)
{
  this_set = list()
  for(state in States)
  {
    this_s <- predict(m, state)
    c <- cor(state$deaths_per_thou, y = this_s)
    if(c$estimate[[1]] > 0.95)
    {
      append(this_set, state$Province_State)
    }
  }
  append(sets, this_set)
}
options(warn=1)
```