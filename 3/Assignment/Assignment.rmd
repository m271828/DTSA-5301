---
title: "Week 3 Assignment"
author: "Erin Chapman"
date: "1/16/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
install.packages("tidyverse")
library(tidyverse)
```

## Step 2: Data Set and Cleanup
For this assignment we are looking at historical from NYPD. Specifically every shooting incident since 2006. Jurisdiction code is not 0 in only 3954 rows, 54 of which are 1 and 3900 are 2. This data is likely irrelevant to analysis and can be dropped given the minimal variation. Location description is only set in 10004 shootings. This was describing housing types primarily. Since this is roughly half the records, we'll consider the rest as unknowns. Perpetrator age group isn't known in 8295 rows, sex in 8261, and race in 8261. It's easier to identify sex and race than a specific age range, so the slight variation is not concerning. The perpetrator information would only be known on conviction so the high number of empty values is also unconcerning and should just be treated as unknowns. All other data exists in the 23585 rows. The location is replicated 3 times and could be reduced to a single lat/lon pair.

```{r importData}
url_in <-"https://data.cityofnewyork.us/api/views/833y-fsy8/rows.csv?accessType=DOWNLOAD"
csv_data <- read.csv(url_in)
summary(csv_data)
csv_data$OCCUR_DATE <- lubridate::mdy(csv_data$OCCUR_DATE, tz = "EST")
csv_data$OCCUR_TIME <- hms::hms(lubridate::hms(csv_data$OCCUR_TIME))
csv_data$STATISTICAL_MURDER_FLAG <- as.logical(csv_data$STATISTICAL_MURDER_FLAG)
summary(csv_data)
```

I'd like to see if shootings are clustered in certain areas and year over year trends in whether there was an increase or decrease in deaths. Particularly if the direction trend was fairly stable across regions or are there outliers that change. I'd then compare those outliers with the areas with clustered shootings to see if there's a correlation. I'd start with the high level view of by boro and then look at it with a more finer grain by precinct. Race would potentially be interesting to look at but this dataset isn't complete enough to do a breakdown by race since only half the shootings have that data.

This means I don't need the INCIDENT_KEY for my analysis since it's just a unique identifier. I will need the OCCUR_DATE field but right now just the year. Since we're only looking at 18 years of data we may need more data points so month information should be left in as well. I won't need OCCUR_TIME and can drop that. BORO and PRECINCT as controlled variables for analysis I obviously want to keep in. JURISDICTION_CODE, LOCATION_DESC I can drop. I'd like to keep the STATISTICAL_MURDER_FLAG for now since comparing the two may be interesting and it might help with finding clusters later. PERP_* and VIC_* demographics I obviously don't need as well as the X and Y coordinates, Latitude, Longitude and Lon_Lat because that would have me analyzing too fine grained data if I did. Those locations are likely too specific to tell me anything about how regions trended over time.

```{r DropCols, echo=TRUE}
csv_data <- select(csv_data, -c(INCIDENT_KEY, OCCUR_TIME, JURISDICTION_CODE, LOCATION_DESC, PERP_AGE_GROUP, PERP_SEX, PERP_RACE, VIC_AGE_GROUP, VIC_SEX, VIC_RACE, X_COORD_CD, Y_COORD_CD, Latitude, Longitude, Lon_Lat))
summary(csv_data)
```

Now instead of having OCCUR_DATE be a column, I'd like to make a row for each month and year. For the next step, instead of adding additional columns to my data set, I'm actually going to create four new data frames:
1. For each Boro/Precinct location, count how many incidents occurred in a month
1. For each Boro/Precinct location, count how many incidents occurred in a year
1. For each Boro, count how many incidents occurred in a month
1. For each Boro, count how many incidents occurred in a year

```{r MassageData, echo = TRUE}
csv_data <- add_column(csv_data, tibble(MONTH = lubridate::month(csv_data$OCCUR_DATE), YEAR = lubridate::year(csv_data$OCCUR_DATE)))
csv_data <- select(csv_data, -c(OCCUR_DATE))

p_monthly_incidents <- csv_data %>% count(BORO, PRECINCT, MONTH, YEAR)
p_yearly_incidents <- csv_data %>% count(BORO, PRECINCT, YEAR)
b_monthly_incidents <- csv_data %>% count(BORO, Month, Year)
b_yearly_incidents <- csv_data %>% count(BORO, Year)

print(p_monthly_incidents, max = 5)
print(p_yearly_incidents, max = 5)
print(b_monthly_incidents, max = 4)
print(b_yearly_incidents, max = 4)
```

You can see from the sample lines that it's an easier way view the data instead of adding monthly and yearly columns to the existing data frame for each precinct (and then either add repetitive extra columns for the boro totals in each precinct or have to calculate them every time I need them). This also allows me to preserve the STATISTICAL_MURDER_FLAG in case I do want to use it for analysis in the future.

## Step 3: Visualizations
Before getting into charts, I'd like to do some quick summary math that will help with interpreting the graph and set expectations for what I'll see. These will be very quick statistics: mean, median, standard deviation and variance. I want to see them two different ways for each data frame, looking at variance within precinct or boro over time and then across the entire data frame.

2 visualizations and some analysis
```{r session, echo=FALSE}
sessionInfo()
```
